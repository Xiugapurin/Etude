{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dc2ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from corpus import Synchronizer\n",
    "\n",
    "def calculate_wps(origin_path: str, cover_path: str, song_dir: str, lambda_val: float = 0.1) -> float:\n",
    "    try:\n",
    "        s = Synchronizer()\n",
    "        wp = s.get_wp(origin_path, cover_path, song_dir)\n",
    "        \n",
    "        t_cover = s.t1\n",
    "        t_orig = s.t2\n",
    "        \n",
    "        if t_cover is None or t_orig is None:\n",
    "            raise ValueError(\"æ™‚é–“æˆ³åºåˆ—æœªèƒ½æˆåŠŸåœ¨ Synchronizer ç‰©ä»¶ä¸­ç”Ÿæˆã€‚\")\n",
    "\n",
    "        wp_int = wp.astype(int)\n",
    "\n",
    "        indices_cover = wp_int[0]\n",
    "        indices_orig = wp_int[1]\n",
    "\n",
    "        time_diff_sequence = t_orig[indices_orig] - t_cover[indices_cover]\n",
    "\n",
    "        sigma_d = np.std(time_diff_sequence)\n",
    "        print(f\"wp-std: {sigma_d}\")\n",
    "        wps_score = np.exp(-lambda_val * sigma_d)\n",
    "\n",
    "        return wps_score\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"è¨ˆç®— WPS åˆ†æ•¸æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}\")\n",
    "        return 0.0\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    target_dir = \"CPOP4\"\n",
    "    song_dir = f\"./dataset/eval/{target_dir}\"\n",
    "    original_audio = f\"{song_dir}/origin.wav\"\n",
    "    versions = [\"picogen\", \"amtapc\", \"music2midi\", \"human\"]\n",
    "\n",
    "    for v in versions:\n",
    "        cover_audio = f\"{song_dir}/{v}.wav\"\n",
    "        wps_score = calculate_wps(original_audio, cover_audio, song_dir, 0.25)\n",
    "\n",
    "        if wps_score > 0:\n",
    "            print(f\"WPS of {v}: {wps_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c52428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_nwpd(origin_path: str, cover_path: str, song_dir: str, lambda_nwpd: float = 1.0) -> float:\n",
    "    try:\n",
    "        s = Synchronizer()\n",
    "        wp = s.get_wp(origin_path, cover_path, song_dir)\n",
    "        \n",
    "        t_cover = s.t1\n",
    "        t_orig = s.t2\n",
    "        \n",
    "        if t_cover is None or t_orig is None:\n",
    "            raise ValueError(\"æ™‚é–“æˆ³åºåˆ—æœªèƒ½æˆåŠŸåœ¨ Synchronizer ç‰©ä»¶ä¸­ç”Ÿæˆã€‚\")\n",
    "\n",
    "        wp_int = wp.astype(int)\n",
    "\n",
    "        path_t_cover = t_cover[wp_int[0]]\n",
    "        path_t_orig = t_orig[wp_int[1]]\n",
    "\n",
    "        coeffs = np.polyfit(path_t_cover, path_t_orig, 1)\n",
    "        a, b = coeffs[0], coeffs[1]\n",
    "\n",
    "        t_orig_predicted = a * path_t_cover + b\n",
    "        \n",
    "        deviation = path_t_orig - t_orig_predicted\n",
    "\n",
    "        sigma_dev = np.std(deviation)\n",
    "\n",
    "        nwpd_score = np.exp(-lambda_nwpd * sigma_dev)\n",
    "\n",
    "        return nwpd_score\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"è¨ˆç®— NWPD åˆ†æ•¸æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}\")\n",
    "        return 0.0\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    target_dir = \"JPOP1\"\n",
    "    song_dir = f\"./dataset/eval/{target_dir}\"\n",
    "    original_audio = f\"{song_dir}/origin.wav\"\n",
    "    versions = [\"picogen\", \"amtapc\", \"music2midi\", \"human\"]\n",
    "\n",
    "    for v in versions:\n",
    "        cover_audio = f\"{song_dir}/{v}.wav\"\n",
    "        nwpd_score = calculate_nwpd(original_audio, cover_audio, song_dir, 0.25)\n",
    "\n",
    "        if nwpd_score > 0:\n",
    "            print(f\"NWPD of {v}: {nwpd_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa20ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from corpus import Synchronizer\n",
    "\n",
    "def calculate_nwpd(origin_path: str, cover_path: str, song_dir: str, lambda_nwpd: float = 1.0) -> float:\n",
    "    \"\"\"\n",
    "    è¨ˆç®—æ­£è¦åŒ–è·¯å¾‘åå·® (Normalized Warp Path Deviation, NWPD) åˆ†æ•¸ã€‚\n",
    "    æ­¤ç‰ˆæœ¬å·²æ ¹æ“š wp çš„å¯¦éš› shape (2, L) é€²è¡Œä¿®æ­£ã€‚\n",
    "    \"\"\"\n",
    "    try:\n",
    "        s = Synchronizer()\n",
    "        wp = s.get_wp(origin_path, cover_path, song_dir)\n",
    "        \n",
    "        t_cover = s.t1\n",
    "        t_orig = s.t2\n",
    "        \n",
    "        if t_cover is None or t_orig is None:\n",
    "            raise ValueError(\"æ™‚é–“æˆ³åºåˆ—æœªèƒ½æˆåŠŸåœ¨ Synchronizer ç‰©ä»¶ä¸­ç”Ÿæˆã€‚\")\n",
    "\n",
    "        wp_int = wp.astype(int)\n",
    "        path_t_cover = t_cover[wp_int[0]]\n",
    "        path_t_orig = t_orig[wp_int[1]]\n",
    "\n",
    "        coeffs = np.polyfit(path_t_cover, path_t_orig, 1)\n",
    "        a, b = coeffs[0], coeffs[1]\n",
    "\n",
    "        t_orig_predicted = a * path_t_cover + b\n",
    "        deviation = path_t_orig - t_orig_predicted\n",
    "        sigma_dev = np.std(deviation)\n",
    "        nwpd_score = np.exp(-lambda_nwpd * sigma_dev)\n",
    "        return nwpd_score\n",
    "    except Exception as e:\n",
    "        print(f\"è¨ˆç®— NWPD åˆ†æ•¸æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}\")\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def analyze_and_visualize_scores():\n",
    "    \"\"\"\n",
    "    ä¸»å‡½å¼ï¼šè¨ˆç®—æ‰€æœ‰æ­Œæ›²å„ç‰ˆæœ¬çš„ NWPD åˆ†æ•¸ï¼Œè¨ˆç®—å¹³å‡å€¼ï¼Œä¸¦é€²è¡Œè¦–è¦ºåŒ–ã€‚\n",
    "    \"\"\"\n",
    "    # --- 1. è¨­å®š ---\n",
    "    base_dir = os.path.join(\".\", \"dataset\", \"eval\")\n",
    "    metadata_path = os.path.join(base_dir, \"metadata.json\")\n",
    "    origin_filename = \"origin.wav\"\n",
    "    versions = [\"human\", \"picogen\", \"amtapc\", \"music2midi\"]\n",
    "    lambda_val = 0.5\n",
    "    \n",
    "    # ç”¨æ–¼å„²å­˜æ‰€æœ‰åˆ†æ•¸çš„å­—å…¸\n",
    "    scores_by_version = {v: [] for v in versions}\n",
    "\n",
    "    # --- 2. è®€å– metadata ä¸¦è¨ˆç®—åˆ†æ•¸ ---\n",
    "    try:\n",
    "        with open(metadata_path, 'r', encoding='utf-8') as f:\n",
    "            metadata = json.load(f)\n",
    "        # print(f\"âœ… æˆåŠŸè®€å– metadata.jsonï¼Œå…±æ‰¾åˆ° {len(metadata)} é¦–æ­Œæ›²ã€‚\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° metadata.json æª”æ¡ˆã€‚\")\n",
    "        return\n",
    "\n",
    "    for i, song_data in enumerate(metadata):\n",
    "        dir_name = song_data.get(\"dir_name\")\n",
    "        if not dir_name:\n",
    "            continue\n",
    "\n",
    "        song_dir = os.path.join(base_dir, dir_name)\n",
    "        # print(f\"\\nğŸµ æ­£åœ¨è™•ç†æ­Œæ›²: {song_dir} ({i+1}/{len(metadata)})\")\n",
    "\n",
    "        origin_path = os.path.join(song_dir, origin_filename)\n",
    "        if not os.path.exists(origin_path):\n",
    "            print(f\"  â†ªï¸ å·²è·³é (æ‰¾ä¸åˆ° origin.wav)\")\n",
    "            continue\n",
    "\n",
    "        for v in versions:\n",
    "            cover_path = os.path.join(song_dir, f\"{v}.wav\")\n",
    "            if not os.path.exists(cover_path):\n",
    "                print(f\"  â†ªï¸ å·²è·³éç‰ˆæœ¬ '{v}' (æ‰¾ä¸åˆ° {v}.wav) {song_dir}\")\n",
    "                continue\n",
    "            \n",
    "            # è¨ˆç®—åˆ†æ•¸\n",
    "            score = calculate_nwpd(origin_path, cover_path, song_dir, lambda_nwpd=lambda_val)\n",
    "            if score > 0:\n",
    "                # print(f\"  ğŸ“Š ç‰ˆæœ¬ '{v}' çš„ NWPD åˆ†æ•¸: {score:.4f}\")\n",
    "                scores_by_version[v].append(score)\n",
    "\n",
    "    # --- 3. è¨ˆç®—ä¸¦æ‰“å°å¹³å‡åˆ†æ•¸ ---\n",
    "    print(\"\\n\\n--- å¹³å‡åˆ†æ•¸çµ±è¨ˆ ---\")\n",
    "    average_scores = {}\n",
    "    for version, scores in scores_by_version.items():\n",
    "        if scores:\n",
    "            avg_score = np.mean(scores)\n",
    "            average_scores[version] = avg_score\n",
    "            print(f\"ç‰ˆæœ¬ {version:<12}: å¹³å‡ NWPD åˆ†æ•¸ = {avg_score:.4f} (åŸºæ–¼ {len(scores)} å€‹æ¨£æœ¬)\")\n",
    "        else:\n",
    "            print(f\"ç‰ˆæœ¬ {version:<12}: ç„¡æœ‰æ•ˆåˆ†æ•¸å¯ä¾›è¨ˆç®—ã€‚\")\n",
    "    \n",
    "    # --- 4. æ•¸æ“šè¦–è¦ºåŒ– ---\n",
    "    print(\"\\nğŸ¨ æ­£åœ¨ç”Ÿæˆåˆ†æ•¸åˆ†ä½ˆåœ–...\")\n",
    "    \n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "    # ç‚ºæ¯å€‹ç‰ˆæœ¬ç¹ªè£½ä¸€æ¢ KDE æ›²ç·š\n",
    "    for version, scores in scores_by_version.items():\n",
    "        if scores:\n",
    "            sns.kdeplot(scores, label=version, fill=True, alpha=0.5, ax=ax, lw=2.5)\n",
    "\n",
    "    ax.set_title('NWPD Score Distribution by Version', fontsize=16, pad=20)\n",
    "    ax.set_xlabel('NWPD Score', fontsize=12)\n",
    "    ax.set_ylabel('Density', fontsize=12)\n",
    "    ax.set_xlim(0, 1.05)\n",
    "    ax.legend(title='Version', fontsize=10)\n",
    "    \n",
    "    # å„²å­˜åœ–è¡¨\n",
    "    output_image_path = \"nwpd_score_distribution.png\"\n",
    "    plt.savefig(output_image_path, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    print(f\"âœ… åˆ†æ•¸åˆ†ä½ˆåœ–å·²æˆåŠŸå„²å­˜è‡³: {output_image_path}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    analyze_and_visualize_scores()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
