{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dc2ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from corpus import Synchronizer\n",
    "\n",
    "def calculate_wps(origin_path: str, cover_path: str, song_dir: str, lambda_val: float = 0.1) -> float:\n",
    "    try:\n",
    "        s = Synchronizer()\n",
    "        wp = s.get_wp(origin_path, cover_path, song_dir)\n",
    "        \n",
    "        t_cover = s.t1\n",
    "        t_orig = s.t2\n",
    "        \n",
    "        if t_cover is None or t_orig is None:\n",
    "            raise ValueError(\"時間戳序列未能成功在 Synchronizer 物件中生成。\")\n",
    "\n",
    "        wp_int = wp.astype(int)\n",
    "\n",
    "        indices_cover = wp_int[0]\n",
    "        indices_orig = wp_int[1]\n",
    "\n",
    "        time_diff_sequence = t_orig[indices_orig] - t_cover[indices_cover]\n",
    "\n",
    "        sigma_d = np.std(time_diff_sequence)\n",
    "        print(f\"wp-std: {sigma_d}\")\n",
    "        wps_score = np.exp(-lambda_val * sigma_d)\n",
    "\n",
    "        return wps_score\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"計算 WPS 分數時發生錯誤：{e}\")\n",
    "        return 0.0\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    target_dir = \"CPOP4\"\n",
    "    song_dir = f\"./dataset/eval/{target_dir}\"\n",
    "    original_audio = f\"{song_dir}/origin.wav\"\n",
    "    versions = [\"picogen\", \"amtapc\", \"music2midi\", \"human\"]\n",
    "\n",
    "    for v in versions:\n",
    "        cover_audio = f\"{song_dir}/{v}.wav\"\n",
    "        wps_score = calculate_wps(original_audio, cover_audio, song_dir, 0.25)\n",
    "\n",
    "        if wps_score > 0:\n",
    "            print(f\"WPS of {v}: {wps_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa20ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from corpus import Synchronizer\n",
    "\n",
    "def calculate_nwpd(origin_path: str, cover_path: str, song_dir: str, lambda_nwpd: float = 1.0) -> float:\n",
    "    \"\"\"\n",
    "    計算正規化路徑偏差 (Normalized Warp Path Deviation, NWPD) 分數。\n",
    "    此版本已根據 wp 的實際 shape (2, L) 進行修正。\n",
    "    \"\"\"\n",
    "    try:\n",
    "        s = Synchronizer()\n",
    "        wp = s.get_wp(origin_path, cover_path, song_dir)\n",
    "        \n",
    "        t_cover = s.t1\n",
    "        t_orig = s.t2\n",
    "        \n",
    "        if t_cover is None or t_orig is None:\n",
    "            raise ValueError(\"時間戳序列未能成功在 Synchronizer 物件中生成。\")\n",
    "\n",
    "        wp_int = wp.astype(int)\n",
    "        path_t_cover = t_cover[wp_int[0]]\n",
    "        path_t_orig = t_orig[wp_int[1]]\n",
    "\n",
    "        coeffs = np.polyfit(path_t_cover, path_t_orig, 1)\n",
    "        a, b = coeffs[0], coeffs[1]\n",
    "\n",
    "        t_orig_predicted = a * path_t_cover + b\n",
    "        deviation = path_t_orig - t_orig_predicted\n",
    "        sigma_dev = np.std(deviation)\n",
    "        nwpd_score = np.exp(-lambda_nwpd * sigma_dev)\n",
    "        return nwpd_score\n",
    "    except Exception as e:\n",
    "        print(f\"計算 NWPD 分數時發生錯誤：{e}\")\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "def analyze_and_visualize_scores():\n",
    "    \"\"\"\n",
    "    主函式：計算所有歌曲各版本的 NWPD 分數，計算平均值，並進行視覺化。\n",
    "    \"\"\"\n",
    "    # --- 1. 設定 ---\n",
    "    base_dir = os.path.join(\".\", \"dataset\", \"eval\")\n",
    "    metadata_path = os.path.join(base_dir, \"metadata.json\")\n",
    "    origin_filename = \"origin.wav\"\n",
    "    versions = [\"human\", \"picogen\", \"amtapc\", \"music2midi\"]\n",
    "    lambda_val = 0.5\n",
    "    \n",
    "    # 用於儲存所有分數的字典\n",
    "    scores_by_version = {v: [] for v in versions}\n",
    "\n",
    "    # --- 2. 讀取 metadata 並計算分數 ---\n",
    "    try:\n",
    "        with open(metadata_path, 'r', encoding='utf-8') as f:\n",
    "            metadata = json.load(f)\n",
    "        # print(f\"✅ 成功讀取 metadata.json，共找到 {len(metadata)} 首歌曲。\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"❌ 錯誤：找不到 metadata.json 檔案。\")\n",
    "        return\n",
    "\n",
    "    for i, song_data in enumerate(metadata):\n",
    "        dir_name = song_data.get(\"dir_name\")\n",
    "        if not dir_name:\n",
    "            continue\n",
    "\n",
    "        song_dir = os.path.join(base_dir, dir_name)\n",
    "        # print(f\"\\n🎵 正在處理歌曲: {song_dir} ({i+1}/{len(metadata)})\")\n",
    "\n",
    "        origin_path = os.path.join(song_dir, origin_filename)\n",
    "        if not os.path.exists(origin_path):\n",
    "            print(f\"  ↪️ 已跳過 (找不到 origin.wav)\")\n",
    "            continue\n",
    "\n",
    "        for v in versions:\n",
    "            cover_path = os.path.join(song_dir, f\"{v}.wav\")\n",
    "            if not os.path.exists(cover_path):\n",
    "                print(f\"  ↪️ 已跳過版本 '{v}' (找不到 {v}.wav) {song_dir}\")\n",
    "                continue\n",
    "            \n",
    "            # 計算分數\n",
    "            score = calculate_nwpd(origin_path, cover_path, song_dir, lambda_nwpd=lambda_val)\n",
    "            if score > 0:\n",
    "                # print(f\"  📊 版本 '{v}' 的 NWPD 分數: {score:.4f}\")\n",
    "                scores_by_version[v].append(score)\n",
    "\n",
    "    # --- 3. 計算並打印平均分數 ---\n",
    "    print(\"\\n\\n--- 平均分數統計 ---\")\n",
    "    average_scores = {}\n",
    "    for version, scores in scores_by_version.items():\n",
    "        if scores:\n",
    "            avg_score = np.mean(scores)\n",
    "            average_scores[version] = avg_score\n",
    "            print(f\"版本 {version:<12}: 平均 NWPD 分數 = {avg_score:.4f} (基於 {len(scores)} 個樣本)\")\n",
    "        else:\n",
    "            print(f\"版本 {version:<12}: 無有效分數可供計算。\")\n",
    "    \n",
    "    # --- 4. 數據視覺化 ---\n",
    "    print(\"\\n🎨 正在生成分數分佈圖...\")\n",
    "    \n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "    # 為每個版本繪製一條 KDE 曲線\n",
    "    for version, scores in scores_by_version.items():\n",
    "        if scores:\n",
    "            sns.kdeplot(scores, label=version, fill=True, alpha=0.5, ax=ax, lw=2.5)\n",
    "\n",
    "    ax.set_title('NWPD Score Distribution by Version', fontsize=16, pad=20)\n",
    "    ax.set_xlabel('NWPD Score', fontsize=12)\n",
    "    ax.set_ylabel('Density', fontsize=12)\n",
    "    ax.set_xlim(0, 1.05)\n",
    "    ax.legend(title='Version', fontsize=10)\n",
    "    \n",
    "    # 儲存圖表\n",
    "    output_image_path = \"nwpd_score_distribution.png\"\n",
    "    plt.savefig(output_image_path, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    print(f\"✅ 分數分佈圖已成功儲存至: {output_image_path}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    analyze_and_visualize_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9b8e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import IPECalculator\n",
    "\n",
    "# 初始化計算器。這裡的 mu 和 sigma 應該根據您的資料集進行設定\n",
    "# n_clusters 也是一個重要的超參數，會影響符號的粒度\n",
    "ipe_calc = IPECalculator(n_gram=8, n_clusters=16, mu_entropy=4.5, sigma_entropy=0.5)\n",
    "\n",
    "# 假設您有一個 MIDI 檔案列表\n",
    "midi_files = [\"./dataset/eval/JPOP1/cover.mid\", \"./dataset/eval/JPOP1/picogen.mid\", \"./dataset/eval/JPOP1/amtapc.mid\", \"./dataset/eval/JPOP1/music2midi.mid\"]\n",
    "\n",
    "for midi_file in midi_files:\n",
    "    print(f\"\\nAnalyzing {midi_file}...\")\n",
    "    results = ipe_calc.calculate_ipe(midi_file)\n",
    "\n",
    "    if \"error\" in results:\n",
    "        print(f\"  Error: {results['error']}\")\n",
    "    else:\n",
    "        # 打印完整的計算結果\n",
    "        print(\"  IPE Score: {:.4f}\".format(results['ipe_score']))\n",
    "        print(\"  Shannon Entropy: {:.4f}\".format(results['shannon_entropy']))\n",
    "        print(\"  N-gram Count: {}\".format(results['n_gram_count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db4f80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm # 用於顯示進度條\n",
    "\n",
    "from evaluation import IPECalculator\n",
    "\n",
    "def analyze_dataset_for_ipe_params():\n",
    "    \"\"\"\n",
    "    遍歷資料集，計算所有人類演奏的香農熵，並輸出統計數據以決定 IPE 參數。\n",
    "    \"\"\"\n",
    "    dataset_dir = \"./dataset/synced/\"\n",
    "    if not os.path.exists(dataset_dir):\n",
    "        print(f\"錯誤：找不到資料集目錄 {dataset_dir}\")\n",
    "        return\n",
    "\n",
    "    # 初始化計算器。mu 和 sigma 在這裡不重要，但 n_gram 和 n_clusters 會影響熵的計算\n",
    "    ipe_calculator = IPECalculator(n_gram=8, n_clusters=16)\n",
    "    \n",
    "    entropy_values = []\n",
    "    \n",
    "    # 獲取所有子目錄\n",
    "    subdirectories = [d for d in os.scandir(dataset_dir) if d.is_dir()]\n",
    "    \n",
    "    print(f\"正在分析 {len(subdirectories)} 首人類演奏歌曲...\")\n",
    "    \n",
    "    # 使用 tqdm 顯示進度條\n",
    "    for entry in tqdm(subdirectories, desc=\"Analyzing songs\"):\n",
    "        json_path = os.path.join(entry.path, \"cover.json\")\n",
    "        \n",
    "        if os.path.exists(json_path):\n",
    "            # 我們只需要計算熵值\n",
    "            results = ipe_calculator.calculate_ipe(json_path)\n",
    "            if \"shannon_entropy\" in results:\n",
    "                entropy_values.append(results[\"shannon_entropy\"])\n",
    "\n",
    "    if not entropy_values:\n",
    "        print(\"未能在資料集中計算出任何熵值。\")\n",
    "        return\n",
    "        \n",
    "    # --- 統計分析 ---\n",
    "    entropy_series = pd.Series(entropy_values)\n",
    "    stats = entropy_series.describe()\n",
    "    \n",
    "    mean_entropy = stats['mean']\n",
    "    std_entropy = stats['std']\n",
    "    \n",
    "    print(\"\\n\\n--- 人類演奏資料集熵值統計分析 ---\")\n",
    "    print(stats)\n",
    "    \n",
    "    print(\"\\n--- 建議的 IPE 參數值 ---\")\n",
    "    print(f\"建議的 𝜇_Hn (mu_entropy): {mean_entropy:.4f}\")\n",
    "    print(f\"建議的 σ_c (sigma_entropy): {std_entropy:.4f}  (這是一個好的起始點，您可以根據需要調整)\")\n",
    "\n",
    "    # --- 視覺化 ---\n",
    "    print(\"\\n正在生成熵值分佈圖...\")\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(entropy_series, kde=True, bins=50)\n",
    "    plt.axvline(mean_entropy, color='r', linestyle='--', label=f'Mean: {mean_entropy:.2f}')\n",
    "    plt.axvline(mean_entropy + std_entropy, color='g', linestyle=':', label=f'+1 Std Dev: {mean_entropy + std_entropy:.2f}')\n",
    "    plt.axvline(mean_entropy - std_entropy, color='g', linestyle=':', label=f'-1 Std Dev: {mean_entropy - std_entropy:.2f}')\n",
    "    plt.title('人類演奏資料集的香農熵 (H_n) 分佈', fontsize=16)\n",
    "    plt.xlabel('Shannon Entropy', fontsize=12)\n",
    "    plt.ylabel('歌曲數量 (Count)', fontsize=12)\n",
    "    plt.legend()\n",
    "    plt.savefig(\"ipe_entropy_distribution.png\", dpi=300)\n",
    "    print(\"✅ 熵值分佈圖已儲存為 ipe_entropy_distribution.png\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 安裝必要的函式庫\n",
    "    # pip install pandas matplotlib seaborn tqdm\n",
    "    analyze_dataset_for_ipe_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8156e77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 假設您的 IpeCalculator 類別儲存在 evaluation/IPE.py\n",
    "from evaluation.IPE import IPECalculator \n",
    "\n",
    "def evaluate_models_with_ipe():\n",
    "    \"\"\"\n",
    "    使用校準後的 IPE 參數，評估 eval 資料集中各個模型的表現。\n",
    "    \"\"\"\n",
    "    # --- 1. 設定 ---\n",
    "    eval_dir = \"./dataset/eval\"\n",
    "    metadata_path = os.path.join(eval_dir, \"metadata.json\")\n",
    "    versions = [\"cover\", \"picogen\", \"amtapc\", \"music2midi\"]\n",
    "    \n",
    "    # 使用您從 4751 首歌曲中分析出的黃金參數\n",
    "    EMPIRICAL_MU = 10.8956\n",
    "    EMPIRICAL_SIGMA = 0.6923\n",
    "    \n",
    "    # 初始化計算器\n",
    "    ipe_calculator = IPECalculator(\n",
    "        mu_entropy=EMPIRICAL_MU, \n",
    "        sigma_entropy=EMPIRICAL_SIGMA,\n",
    "        n_gram=8, \n",
    "        n_clusters=16 # 確保與分析時的參數一致\n",
    "    )\n",
    "\n",
    "    # --- 2. 讀取 metadata 並計算分數 ---\n",
    "    try:\n",
    "        with open(metadata_path, 'r', encoding='utf-8') as f:\n",
    "            metadata = json.load(f)\n",
    "        print(f\"✅ 成功讀取 metadata.json，將分析 {len(metadata)} 首歌曲。\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"❌ 錯誤：找不到 metadata.json 檔案。\")\n",
    "        return\n",
    "\n",
    "    results_list = []\n",
    "    for song_data in tqdm(metadata, desc=\"Evaluating Songs\"):\n",
    "        dir_name = song_data.get(\"dir_name\")\n",
    "        if not dir_name: continue\n",
    "\n",
    "        song_dir = os.path.join(eval_dir, dir_name)\n",
    "        \n",
    "        for version in versions:\n",
    "            midi_path = os.path.join(song_dir, f\"{version}.mid\")\n",
    "            if not os.path.exists(midi_path): continue\n",
    "\n",
    "            results = ipe_calculator.calculate_ipe(midi_path)\n",
    "            if \"error\" not in results:\n",
    "                results_list.append({\n",
    "                    \"song\": dir_name,\n",
    "                    \"version\": version,\n",
    "                    \"ipe_score\": results[\"ipe_score\"],\n",
    "                    \"entropy\": results[\"shannon_entropy\"]\n",
    "                })\n",
    "\n",
    "    # --- 3. 使用 Pandas 進行統計分析 ---\n",
    "    if not results_list:\n",
    "        print(\"未計算出任何有效分數。\")\n",
    "        return\n",
    "\n",
    "    df = pd.DataFrame(results_list)\n",
    "    \n",
    "    print(\"\\n\\n--- 各版本 IPE 分數統計摘要 ---\")\n",
    "    # 根據平均分數進行排序\n",
    "    summary = df.groupby('version')['ipe_score'].describe().sort_values('mean', ascending=False)\n",
    "    print(summary)\n",
    "    \n",
    "    print(\"\\n--- 各版本平均熵值 (與理想值 10.8956 比較) ---\")\n",
    "    mean_entropy = df.groupby('version')['entropy'].mean().sort_values(ascending=False)\n",
    "    print(mean_entropy)\n",
    "\n",
    "    # --- 4. 數據視覺化 ---\n",
    "    print(\"\\n🎨 正在生成分數分佈的箱形圖 (Box Plot)...\")\n",
    "    \n",
    "    # 根據平均分對版本進行排序，讓圖表更清晰\n",
    "    order = summary.index \n",
    "    \n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    sns.boxplot(data=df, x='ipe_score', y='version', order=order, palette='viridis')\n",
    "    \n",
    "    plt.title('各版本 IPE 分數分佈比較', fontsize=18, pad=20)\n",
    "    plt.xlabel('IPE Score (越高越好)', fontsize=14)\n",
    "    plt.ylabel('版本 (Version)', fontsize=14)\n",
    "    plt.xlim(-0.05, 1.05)\n",
    "    plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    output_image_path = \"ipe_evaluation_results.png\"\n",
    "    plt.savefig(output_image_path, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    print(f\"✅ 評估結果圖表已成功儲存至: {output_image_path}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    evaluate_models_with_ipe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
