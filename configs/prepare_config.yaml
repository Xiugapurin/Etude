# Unified configuration for the entire dataset preparation pipeline.

# --- Stage 1: Download ---
download:
  output_dir: "dataset/raw"
  csv_path: "assets/dataset.csv"

# --- Stage 2: Preprocess ---
preprocess:
  output_dir: "dataset/processed"
  beat_model_path: "checkpoints/beat_detector/latest.pt"
  config_path: "configs/structuralize_config.yaml"

  # Configuration for the hFT-Transformer transcription pipeline.
  hft_transformer:
    model_path: "checkpoints/hft_transformer/latest.pkl"
    feature_config_path: "checkpoints/hft_transformer/config.json"
    inference_params:
      mode: "combination"
      thred_mpe: 0.5
      thred_onset: 0.75
      thred_offset: 0.5
      n_stride: 32
      bpm: 120.0

# --- Stage 3: Align & Filter ---
align_and_filter:
  output_dir: "dataset/aligned"
  wp_std_threshold: 1.0

# --- Stage 4: Extract ---
extract:
  output_dir: "dataset/aligned"
  model_path: "checkpoints/extractor/latest.pth"
  config_path: "configs/extract_config.yaml"

# --- Stage 5: Tokenize ---
tokenize:
  output_dir: "dataset/tokenized"
  vocab_path: "dataset/vocab.json"
  save_format: "npy"
