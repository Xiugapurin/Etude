# --- file: run_master_evaluation.py (v4 - Robust Final) ---

import os
import sys
import json
import pandas as pd
from tqdm import tqdm
import seaborn as sns
import matplotlib.pyplot as plt
from pathlib import Path

ROOT = Path(__file__).parent.parent.resolve()
sys.path.insert(0, str(ROOT))

# å‡è¨­æ‚¨çš„è¨ˆç®—å™¨é¡åˆ¥éƒ½ä½æ–¼ evaluation/ ç›®éŒ„ä¸‹
from evaluation import RGCCalculator, IPECalculator, WPDCalculator

def get_genre_from_dirname(dir_name: str) -> str:
    dir_name_upper = dir_name.upper()
    if "CPOP" in dir_name_upper: return "CPOP"
    elif "JPOP" in dir_name_upper: return "JPOP"
    elif "KPOP" in dir_name_upper: return "KPOP"
    elif "WESTERN" in dir_name_upper: return "WESTERN"
    else: return "UNKNOWN"


def run_full_evaluation():
    """
    ä¸»å‡½å¼ï¼šè¨ˆç®— WPD, RGC, IPE ä¸‰å€‹æŒ‡æ¨™ï¼Œä¸¦é€²è¡Œç¶œåˆåˆ†æèˆ‡è¦–è¦ºåŒ–ã€‚
    ã€v4.0 - å·²ä¿®å¾© KeyError ä¸¦å¢åŠ ç©©å¥æ€§ã€‘
    """
    EVAL_DIR = "./dataset/eval"
    METADATA_PATH = os.path.join(EVAL_DIR, "metadata.json")
    VERSIONS = ["cover", "etude_e", "etude_d", "etude_d_d", "picogen", "amtapc", "music2midi"]
    VERSION_DISPLAY_NAMES = {
        "cover": "Human", "etude_e": "Etude Extractor", "etude_d_d": "Etude Decoder - Default",
        "etude_d": "Etude Decoder - Prompted", "picogen": "PiCoGen", "amtapc": "AMT-APC", "music2midi": "Music2MIDI"
    }

    # åƒæ•¸è¨­å®š
    wpd_params = {'subsample_step': 1, 'trim_seconds': 10}
    rgc_params = {'top_k': 8}
    ipe_params = {'n_gram': 8, 'n_clusters': 16}

    print("Initializing calculators...")
    wpd_calc = WPDCalculator(**wpd_params)
    rgc_calc = RGCCalculator(**rgc_params)
    ipe_calc = IPECalculator(**ipe_params)
    
    try:
        with open(METADATA_PATH, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
        if not metadata:
            print(f"âŒ è­¦å‘Šï¼šmetadata.json æª”æ¡ˆç‚ºç©ºï¼Œç„¡æ³•é€²è¡Œåˆ†æã€‚")
            return
        print(f"âœ… æˆåŠŸè®€å– metadata.jsonï¼Œå°‡åˆ†æ {len(metadata)} é¦–æ­Œæ›²ã€‚")
    except FileNotFoundError:
        print(f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° metadata.json æª”æ¡ˆæ–¼ {METADATA_PATH}")
        return
        
    results_list = []
    for song_data in tqdm(metadata, desc="Master Analysis"):
        dir_name = song_data.get("dir_name")
        if not dir_name: continue
        
        song_dir = os.path.join(EVAL_DIR, dir_name)
        origin_wav_path = os.path.join(song_dir, "origin.wav")
        if not os.path.exists(origin_wav_path): continue
            
        for version in VERSIONS:
            wav_path = os.path.join(song_dir, f"{version}.wav")
            mid_path = os.path.join(song_dir, f"{version}.mid")
            
            if not os.path.exists(wav_path) and not os.path.exists(mid_path):
                continue

            result_row = {'song': dir_name, 'version': version}

            wpd_res = wpd_calc.calculate_wpd(origin_wav_path, wav_path, song_dir)
            if "error" not in wpd_res: result_row.update(wpd_res)

            rgc_res = rgc_calc.calculate_rgc(mid_path)
            if "error" not in rgc_res: result_row.update(rgc_res)
                
            ipe_res = ipe_calc.calculate_ipe(mid_path)
            if "error" not in ipe_res: result_row.update(ipe_res)
            
            # ç¢ºä¿è‡³å°‘æœ‰ä¸€å€‹åˆ†æ•¸è¢«æˆåŠŸè¨ˆç®—
            if len(result_row) > 2:
                 results_list.append(result_row)

    # --- 4. åˆ†æèˆ‡å‘ˆç¾ ---
    df_all = pd.DataFrame(results_list)

    # --- ã€é—œéµä¿®æ”¹ #2ã€‘åœ¨é€²è¡Œä»»ä½•æ“ä½œå‰ï¼Œå…ˆæª¢æŸ¥ DataFrame æ˜¯å¦ç‚ºç©º ---
    if df_all.empty:
        print("\nâŒ æœªèƒ½æ”¶é›†åˆ°ä»»ä½•æœ‰æ•ˆçš„è©•åˆ†æ•¸æ“šï¼Œç„¡æ³•ç”Ÿæˆå ±å‘Šå’Œåœ–è¡¨ã€‚")
        print("   è«‹æª¢æŸ¥æ‚¨çš„ eval ç›®éŒ„çµæ§‹ã€æª”æ¡ˆåç¨±ä»¥åŠ metadata.json çš„å…§å®¹æ˜¯å¦æ­£ç¢ºã€‚")
        return
        
    df_all['display_name'] = df_all['version'].map(VERSION_DISPLAY_NAMES).fillna(df_all['version'])

    print("\n\n" + "="*20 + " ç¶œåˆè©•ä¼°å ±å‘Š " + "="*20)
    
    existing_metrics = [col for col in ['wpd_score', 'rgc_score', 'ipe_score'] if col in df_all.columns]
    
    if not existing_metrics:
        print("æ‰€æœ‰æŒ‡æ¨™å‡æœªèƒ½æˆåŠŸè¨ˆç®—ï¼Œç„¡æ³•ç”Ÿæˆå ±å‘Šã€‚")
        return

    # æ‰“å°æ¯å€‹æŒ‡æ¨™çš„è©³ç´°çµ±è¨ˆ
    for metric in existing_metrics:
        print(f"\n--- æŒ‡æ¨™: {metric.upper()} è©³ç´°çµ±è¨ˆ ---")
        summary = df_all.groupby('display_name')[metric].describe().sort_values('mean', ascending=False)
        print(summary)
            
    # æ‰“å°ä¸€å€‹åŒ…å«æ‰€æœ‰æŒ‡æ¨™å¹³å‡å€¼çš„ç¸½è¡¨
    print("\n--- æ‰€æœ‰æŒ‡æ¨™å¹³å‡åˆ†ç¸½è¦½ ---")
    mean_summary = df_all.groupby('display_name')[existing_metrics].mean()
    print(mean_summary.sort_values(existing_metrics[0], ascending=False))

    # --- 5. è¦–è¦ºåŒ– ---
    metrics_to_plot = {
        'WPD Score': 'wpd_score', 'RGC Score': 'rgc_score', 'IPE Score': 'ipe_score'
    }
    plotable_metrics = {title: col for title, col in metrics_to_plot.items() if col in df_all.columns}
    if not plotable_metrics:
        print("ç„¡æ•¸æ“šå¯ä¾›ç¹ªåœ–ã€‚")
        return

    print("\nğŸ¨ æ­£åœ¨ç”Ÿæˆç¶œåˆè©•åˆ†åˆ†ä½ˆåœ–...")
    fig, axes = plt.subplots(len(plotable_metrics), 1, figsize=(12, 8 * len(plotable_metrics)), squeeze=False)
    fig.suptitle('Multi-Metric Evaluation', fontsize=20, y=0.98)
    for i, (title, metric_col) in enumerate(plotable_metrics.items()):
        ax = axes[i, 0]
        order = df_all.groupby('display_name')[metric_col].mean().sort_values(ascending=False).index
        sns.boxplot(data=df_all, x=metric_col, y='display_name', hue='display_name', order=order, palette='viridis', ax=ax, legend=False)
        ax.set_title(title, fontsize=16)
        ax.set_xlabel('Score (Higher is Better)', fontsize=12)
        ax.set_ylabel('Version', fontsize=12)
        ax.set_xlim(-0.05, 1.05)
        ax.grid(axis='x', linestyle='--', alpha=0.7)
    plt.tight_layout(rect=[0, 0, 1, 0.96])
    output_image_path = "master_evaluation_summary.png"
    plt.savefig(output_image_path, dpi=300)
    print(f"âœ… ç¶œåˆè©•ä¼°åœ–è¡¨å·²æˆåŠŸå„²å­˜è‡³: {output_image_path}")


if __name__ == '__main__':
    run_full_evaluation()